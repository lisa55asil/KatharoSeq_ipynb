{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tools\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import qiime2\n",
    "from qiime2 import Artifact\n",
    "from tempfile import mkdtemp\n",
    "from qiime2.plugins import demux, deblur, quality_filter, \\\n",
    "                           metadata, feature_table, alignment, \\\n",
    "                           phylogeny, diversity, emperor, feature_classifier, \\\n",
    "                           taxa, composition\n",
    "from qiime2.plugins import fragment_insertion\n",
    "from qiime2.plugins.fragment_insertion.methods import filter_features\n",
    "from qiime2.plugins.feature_table.methods import filter_samples\n",
    "from qiime2.plugins.feature_table.visualizers import summarize\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pylab\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import raw feature table and taxonomy\n",
    "table = Artifact.load('96057_feature-table.qza')\n",
    "taxonomy = Artifact.load('96057_reference-hit.taxonomy_gg.qza')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collapse and subset data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapsed table to genus level\n",
    "t6 = taxa.methods.collapse(table = table,\n",
    "                           taxonomy = taxonomy,\n",
    "                           level = 6)\n",
    "# import collapsed table as pandas dataframe\n",
    "df = t6.collapsed_table.view(pd.DataFrame)\n",
    "# subset out Zymo mock community samples\n",
    "zymo = df[df.index.str.contains('Zymo')]\n",
    "# ensure table values are numeric\n",
    "zymo = zymo.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick visual check that top 8 taxa make up most of the reads in highest input sample (well A7)\n",
    "max_input = zymo[zymo.index.str.contains(\"A7\")]\n",
    "zymoT = max_input.T\n",
    "zymoT.sort_values(zymoT.columns[0], ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caluclate reads aligning to mock community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of the taxa expected in the zymo community (also the  most abundant in the highest input samples)\n",
    "zymo7taxa = zymoT.sort_values(zymoT.columns[0], ascending = False).head(7).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the total number of reads per sample\n",
    "zymo['deblur_reads'] = zymo.sum(axis=1)\n",
    "# calculate the number of reads aligning to the mock community input genera\n",
    "zymo['zymo_reads'] = zymo[zymo7taxa].sum(axis=1)\n",
    "# calculate the percent correctly assigned\n",
    "zymo['correct_assign'] = zymo['zymo_reads'] / zymo['deblur_reads']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# subset out KatharoSeq columns and add in logarithim of reads for plotting\n",
    "katharo = zymo[['correct_assign','deblur_reads','zymo_reads']]\n",
    "katharo['log_deblur_reads'] = np.log10(katharo['deblur_reads'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit an allosteric sigmoid curve for extrpolating min read count #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define the allosteric sigmoid equation\n",
    "def allosteric_sigmoid(x, h, k_prime):\n",
    "    y = x ** h / (k_prime + x ** h)\n",
    "    return y\n",
    " \n",
    "# fit the curve to your data\n",
    "popt, pcov = curve_fit(allosteric_sigmoid, katharo['log_deblur_reads'], katharo['correct_assign'], method='dogbox')\n",
    "print(popt)\n",
    "# plot fit curve\n",
    "x = np.linspace(0, 5, 50)\n",
    "y = allosteric_sigmoid(x, *popt)\n",
    "\n",
    "# plot the fit\n",
    "pylab.plot(katharo['log_deblur_reads'], katharo['correct_assign'], 'o', label='data')\n",
    "pylab.plot(x,y, label='fit')\n",
    "pylab.ylim(0, 1.05)\n",
    "pylab.ylabel('%reads aligning to mock community')\n",
    "pylab.xlabel('log(quality-filtered reads)')\n",
    "pylab.legend(loc='best')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of reads at which 50% of reads are expected to match input\n",
    "\n",
    "# assign variables and solve for X (number of reads to pass filter)\n",
    "h = popt[0]  # first value printed above graph\n",
    "k = popt[1]   # second value printed above graph\n",
    "y = 0.5 ## what you want to solve for\n",
    "\n",
    "min_log_reads = np.power((k/(1/y-1)),(1/h))\n",
    "min_freq_50 = np.power(10, min_log_reads).astype(int)\n",
    "min_freq_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of reads at which 80% of reads are expected to match input\n",
    "\n",
    "# assign variables and solve for X (number of reads to pass filter)\n",
    "h = popt[0]  # first value printed above graph\n",
    "k = popt[1]   # second value printed above graph\n",
    "y = 0.8 ## what you want to solve for\n",
    "\n",
    "min_log_reads = np.power((k/(1/y-1)),(1/h))\n",
    "min_freq_80 = np.power(10, min_log_reads).astype(int)\n",
    "min_freq_80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of reads at which 90% of reads are expected to match input\n",
    "\n",
    "# assign variables and solve for X (number of reads to pass filter)\n",
    "h = popt[0]  # first value printed above graph\n",
    "k = popt[1]   # second value printed above graph\n",
    "y = 0.9 ## what you want to solve for\n",
    "\n",
    "min_log_reads = np.power((k/(1/y-1)),(1/h))\n",
    "min_freq_90 = np.power(10, min_log_reads).astype(int)\n",
    "min_freq_90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove samples with less than Katharoseq read limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out samples with read counts below what is estimated to achieve 50% accuracy  \n",
    "KS_table_50 = feature_table.methods.filter_samples(table = table,\n",
    "                             min_frequency = min_freq_50)\n",
    "df_50 = KS_table_50.filtered_table.view(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out samples with read counts below what is estimated to achieve 80% accuracy  \n",
    "KS_table_80 = feature_table.methods.filter_samples(table = table,\n",
    "                             min_frequency = min_freq_80)\n",
    "df_80 = KS_table_80.filtered_table.view(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out samples with read counts below what is estimated to achieve 90% accuracy  \n",
    "KS_table_90 = feature_table.methods.filter_samples(table = table,\n",
    "                             min_frequency = min_freq_90)\n",
    "df_90 = KS_table_90.filtered_table.view(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number (and percentage) of samples that are dropped at each filtering threshold\n",
    "print(\"full dataset\", len(df), \"\\n\",\n",
    "      \"50%\", len(df_50), len(df_50)/len(df),\"%\", \"\\n\",\n",
    "      \"80%\", len(df_80), len(df_80)/len(df),\"%\", \"\\n\",\n",
    "      \"90%\", len(df_90), len(df_90)/len(df),\"%\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KS_table_80.filtered_table.save('96057_feature-table-KathSeqFil.qza')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
